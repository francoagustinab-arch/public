{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDdmjJLdNJu2w21zvEFIc/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francoagustinab-arch/public/blob/main/Scrapping_jobs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K852xSM63RF6"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_zonajobs_final_version():\n",
        "    \"\"\"\n",
        "    Versión final y funcional del scraper para Zonajobs.\n",
        "    Utiliza la búsqueda por etiquetas para Título y Detalle para máxima estabilidad.\n",
        "    \"\"\"\n",
        "    # --- Configuración de Selenium para entorno sin pantalla ---\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "    options.add_argument(f'user-agent={user_agent}')\n",
        "\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    start_url = 'https://www.zonajobs.com.ar/empleos-publicacion-menor-a-1-mes.html'\n",
        "    all_jobs = []\n",
        "    page_count = 1\n",
        "\n",
        "    try:\n",
        "        driver.get(start_url)\n",
        "        while True:\n",
        "            print(f\"Scrapeando página {page_count}...\")\n",
        "            # Esperamos a que los avisos sean visibles\n",
        "            WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.CLASS_NAME, 'sc-ktBuXk')))\n",
        "            time.sleep(2) # Pausa para asegurar que todo el JS renderice\n",
        "\n",
        "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "            job_listings = soup.find_all('div', class_='sc-ktBuXk') # Contenedor estable de cada aviso\n",
        "\n",
        "            if not job_listings:\n",
        "                print(\"No se encontraron más avisos en la página.\")\n",
        "                break\n",
        "\n",
        "            for job in job_listings:\n",
        "                try:\n",
        "                    # Título (buscando la etiqueta <h2>)\n",
        "                    title_element = job.find('h2')\n",
        "                    title = title_element.text.strip() if title_element else 'N/A'\n",
        "\n",
        "                    # Empresa (selector estable)\n",
        "                    company_element = job.find(class_='sc-jiTwWT')\n",
        "                    company = company_element.text.strip() if company_element else 'N/A'\n",
        "\n",
        "                    # Detalle del aviso (buscando la etiqueta <p>)\n",
        "                    detail_element = job.find('p')\n",
        "                    detail = detail_element.text.strip() if detail_element else 'N/A'\n",
        "\n",
        "                    # Ubicación y Modo (selectores estables)\n",
        "                    details = job.find_all(class_='sc-jFpLkX')\n",
        "                    location = details[0].text.strip() if len(details) > 0 else 'N/A'\n",
        "                    work_mode = details[1].text.strip() if len(details) > 1 else 'N/A'\n",
        "\n",
        "                    # Enlace (selector estable)\n",
        "                    link_element = job.find('a', class_='sc-ertOQY')\n",
        "                    link = 'https://www.zonajobs.com.ar' + link_element['href'] if link_element and link_element.has_attr('href') else 'N/A'\n",
        "\n",
        "                    all_jobs.append({\n",
        "                        'Titulo': title,\n",
        "                        'Empresa': company,\n",
        "                        'Detalle': detail,\n",
        "                        'Ubicacion': location,\n",
        "                        'Modo de Trabajo': work_mode,\n",
        "                        'Enlace': link\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    print(f\"Error parseando un aviso, continuando... Error: {e}\")\n",
        "\n",
        "            print(f\"Se encontraron {len(job_listings)} avisos en la página {page_count}.\")\n",
        "\n",
        "            # Paginación (selector estable)\n",
        "            try:\n",
        "                next_button = driver.find_element(By.CSS_SELECTOR, 'a.sc-LAuEU.hXefkh')\n",
        "                driver.execute_script(\"arguments[0].click();\", next_button)\n",
        "                page_count += 1\n",
        "                time.sleep(3) # Espera a que la nueva página cargue\n",
        "            except Exception:\n",
        "                print(\"No se encontró el botón 'Siguiente'. Es la última página.\")\n",
        "                break\n",
        "    except Exception as e:\n",
        "        print(f\"Ocurrió un error principal durante el scraping: {e}\")\n",
        "    finally:\n",
        "        driver.quit()\n",
        "\n",
        "    return all_jobs\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Iniciando el proceso de Web Scraping final...\")\n",
        "    jobs_data = scrape_zonajobs_final_version()\n",
        "\n",
        "    if jobs_data:\n",
        "        df = pd.DataFrame(jobs_data)\n",
        "        df.to_csv('base_zonajobs_final.csv', index=False, encoding='utf-8-sig')\n",
        "        print(f\"\\n¡Éxito! Se han exportado {len(jobs_data)} ofertas a 'base_zonajobs_final.csv'\")\n",
        "    else:\n",
        "        print(\"\\nNo se pudo extraer ningún dato.\")"
      ]
    }
  ]
}